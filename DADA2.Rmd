---
title: "R Notebook"
output: github_document
---

```{r}
library(dada2); packageVersion("dada2")
```
#DADA2 search for sequencing errors and correct them so that to reduce the number of unique sequences (genetic variance) obtained

#In this line we indicate rstudio that we want to work with the external package DADA2

```{r}
path <- "/home/rstudio/DADA2/MiSeq_SOP"
list.files(path)
#We named the path to specify a folder where the files that you want to list are located
#The list.files() function is to return a vector containing all the files names that are in our path
```

#One file represent one sample with its respective primer used. In one files more than one sequences (reads) will be present but of the same length but of different quality. Some read will be unique while some reads will be variances or sequencing errors.
```{r}
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))

fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1) #Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
```

#We use the list.files() function to find all files within the "path" that have the pattern "R1_001.fastq" in their name. The full.names = TRUE argument ensures that the full path to each file is included in the returned vector. The result is stored in the variable fnFs
#This is extracting sample names: We use the sapply() function to apply the strsplit() function to each element in the fnFs vector. strsplit() splits each file name based on the underscore character. The first element of each split is extracted using [, 1], and the resulting vector of sample names is stored in the variable sample.names.

#The reason why we've only applied sapply(strsplit(basename(fnFs), "_"),[, 1) to fnFs and not to fnRs is because we're assuming that the sample names are consistent between the R1 and R2 reads.
#sapply(...,[, 1): This applies the function [, which extracts the first element of each vector, to each element in the result of the strsplit operation.

```{r}
#To inspect Inspect read (forward and reverse) quality profiles
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnRs[1:2])

#[1:2] means sample. We can view all the samples quality profile as well

```

#Reverse reads are of significantly worse quality. This isn’t too worrisome, as DADA2 incorporates quality information into its error model which makes the algorithm robust to lower quality sequence, but trimming as the average qualities crash will improve the algorithm’s sensitivity to rare sequence variants. 

#Based on these profiles, we will truncate the reverse reads at position 160 where the quality distribution crashes.
#Reads must still overlap after truncation in order to merge them later


```{r}
#Filter and trim
#Assign the filenames for the filtered fastq.gz files.
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz")) #Place filtered files in filtered/subdirectory
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE)
head(out)

#The filterAndTrim() function from the DADA2 package is being used to filter and trim the fastq files. This step removes low-quality reads and trims the reads to a specific position.

#reads.in: The number of reads in the original file.
#reads.out: The number of reads that passed the filtering and trimming steps.


#The out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160)) line in the DADA2 package is used to filter and trim paired-end fastq files. Here's a breakdown of the arguments:

#fnFs: A vector of file names for the forward reads.
#filtFs: A vector of file names for the filtered forward reads.
#fnRs: A vector of file names for the reverse reads.
#filtRs: A vector of file names for the filtered reverse reads.
#truncLen: A vector of two integers specifying the truncation lengths for the forward and reverse reads, respectively. In this case, the forward reads will be truncated to 240 base pairs and the reverse reads will be truncated to 160 base pairs.

#The filterAndTrim() function performs the following steps: 1)Filters reads: It removes low-quality reads based on their quality scores. 2)Trims reads: It trims the reads to the specified truncation lengths. 3) Writes filtered reads: It writes the filtered reads to the files specified in filtFs and filtRs.
```

#Learn the Error Rates

#Error raterefers to the estimated rate at which sequencing errors occur in the raw sequencing data. These errors can arise from various factors, such as instrument noise, chemical reactions, and sample preparation issues.

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
#The learnErrors() function estimates the error rates for each base position in the filtered reads. This information is used by DADA2 to denoise the data and assign reads to OTUs.
#multithread=TRUE: This argument specifies that the function should use multiple threads to speed up the computation.
```
```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
# Following this analysis we obtain in the environment next to the errR vector "list of 3". The "List of 3" in the context of the DADA2 refers to the three main output objects created during the error rate learning process: 1) errR: This object contains the estimated error rates for each base position in the filtered reads. It is a matrix where each row corresponds to a base position and each column corresponds to a different nucleotide (A, C, G, or T). The values in the matrix represent the probability of a sequencing error occurring at that specific base position. 2) filts: This object is a character vector containing the file paths of the filtered reads. These files are used as input for subsequent steps in the DADA2 pipeline. 3) fnRs: This object is a character vector containing the file paths of the reverse reads. These files are used in conjunction with the forward reads (stored in filts) for paired-end sequencing data. These three objects are essential for the denoising and OTU assignment steps in the DADA2 pipeline, as they provide the necessary information about the sequencing error rates and the filtered read data.
```
```{r}
plotErrors(errF, nominalQ=TRUE) #to visualize the estimated error rates
```

#Sample Inference Analysis
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)

#Ssample inference in DADA2 refers to the process of analyzing sequence data to identify and quantify unique biological sequences (OTUs or ASVs) within a sample. It's a crucial step in understanding the microbial diversity present in a given environment.

#Sample ID: Each row represents a different sample.
#Reads: The total number of sequencing reads obtained for that sample.
#Unique sequences: The number of distinct DNA sequences identified within the sample.
#This information provides a basic overview of the sequencing depth and diversity observed in each sample.

#The DADA2 uses a statistical model to group similar sequences together, assuming that differences between sequences are due to sequencing errors rather than biological variation. This process helps to reduce the number of unique sequences and makes it easier to identify and analyze the dominant microbial populations in the sample. In summary, sample inference in DADA2 is essential for understanding the microbial composition of a sample and for making inferences about the ecological processes occurring within that environment.
```
#The results obtained mean that for each sample (example sample 1, forward) there are 7113 reads (sequences) in which 1979 are unique sequences (that is occur only once)
#The more a species will be present in the sample the more its sequence will be present in the sequencing results. Variance of this species will be considered as other sequences and will form their own OTU. 


#Inspecting the returned dada-class object:
```{r}
dadaFs[[1]]
```
# 1979 input unique sequences: Refers to the total number of unique DNA sequences that were initially identified in the sample after filtering and trimming.
#128 sequence variants: DADA2 grouped these unique sequences into 128 clusters based on their similarity and the estimated error rates. Each cluster represents a unique biological sequence.


```{r}
help("dada-class")
```


#Merge paired reads
#Merge the forward and reverse reads together to obtain the full denoised sequences (constructing the merged “contig” sequences). By default, merged sequences are only output if the forward and reverse reads overlap by at least 12 bases, and are identical to each other in the overlap region (these conditions can be changed via function arguments).


```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE) #Paired reads that did not exactly overlap were removed by mergePairs, further reducing spurious output.
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

#Construct sequence table
#Construction an amplicon sequence variant table (ASV) table, a higher-resolution version of the OTU table produced by traditional methods.
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
#The sequence table is a matrix with rows corresponding to (and named by) the samples, and columns corresponding to (and named by) the sequence variants. This table contains 293 ASVs, and the lengths of our merged sequences all fall within the expected range for this V4 amplicon

#The sequence table summarizes the identified unique sequences (ASVs) and their abundance in the sample. It provides a fundamental overview of the microbial diversity and composition.


#Remove chimeras
#The core dada method corrects substitution and indel errors, but chimeras remain. Fortunately, the accuracy of sequence variants after denoising makes identifying chimeric ASVs simpler. Chimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” sequences.
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
#The frequency of chimeric sequences 
#The frequency of chimeric sequences varies substantially from dataset to dataset, and depends on on factors including experimental procedures and sample complexity.
```{r}
sum(seqtab.nochim)/sum(seqtab)
```
#Here chimeras make up about 21% of the merged sequence variants, but when account for the abundances of those variants we see they account for only about 4% of the merged sequence reads.

#Cautions : Most of your reads should remain after chimera removal (it is not uncommon for a majority of sequence variants to be removed though). If most of your reads were removed as chimeric, upstream processing may need to be revisited. In almost all cases this is caused by primer sequences with ambiguous nucleotides that were not removed prior to beginning the DADA2 pipeline.


#Track reads through the pipeline
#look at the number of reads that made it through each step in the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
#Input: The total number of reads originally present in the sample before any processing.
#Filtered: The number of reads remaining after filtering out low-quality reads based on quality scores.
#Denoisedf: The number of reads remaining after denoising the forward reads (using the estimated error rates).
#Denoisedr: The number of reads remaining after denoising the reverse reads (using the estimated error rates).
#Merged: The number of reads that were successfully merged from paired-end sequencing data (if applicable).
#Nonchim: The number of reads that were not assigned to any chimeric sequence (potential artifacts resulting from PCR errors).


#Assign taxonomy
#The DADA2 package provides a native implementation of the naive Bayesian classifier method for this purpose. The assignTaxonomy function takes as input a set of sequences to be classified and a training set of reference sequences with known taxonomy, and outputs taxonomic assignments with at least minBoot bootstrap confidence.
#We maintain formatted training fastas for the RDP training set, GreenGenes clustered at 97% identity, and the Silva reference database, and additional trainings fastas suitable for protists and certain specific environments have been contributed. For fungal taxonomy, the General Fasta release files from the UNITE ITS database can be used as is.
#To follow along, download the silva_nr_v132_train_set.fa.gz file, and place it in the directory with the fastq files.

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/home/rstudio/DADA2/silva_nr_v132_train_set.fa.gz?download=1", multithread=TRUE)
```


#inspect the taxonomic assignments:
```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```
#nsurprisingly, the Bacteroidetes are well represented among the most abundant taxa in these fecal samples. Few species assignments were made, both because it is often not possible to make unambiguous species assignments from subsegments of the 16S gene, and because there is surprisingly little coverage of the indigenous mouse gut microbiota in reference databases.

```{r}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```
# A mock community is a synthetic mixture of known strains of bacteria. It serves as a controlled experiment because the exact composition is known, allowing for direct comparison between the inferred results and the ground truth. By comparing the inferred sequence variants from the mock community to the expected composition, we can evaluate how well DADA2 performs in terms of identifying and quantifying different bacterial species.

#The evaluation aims to determine the accuracy of DADA2 in identifying the correct sequence variants and their abundances. Error rate calculation: By comparing the inferred results to the known composition of the mock community, the error rate of the DADA2 pipeline can be calculated. The results obtained from the evaluation can be compared to those of other microbiome analysis methods to assess DADA2's performance relative to other tools.


```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
#This mock community contained 20 bacterial strains. DADA2 identified 20 ASVs all of which exactly match the reference genomes of the expected community members. The residual error rate after the DADA2 pipeline for this sample is 0%.



#Optional Analysis# phyloseq

#preparation of data for phyloseq
```{r}
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
theme_set(theme_bw()) #The theme_set(theme_bw()) function in R's ggplot2 package sets the default theme for all subsequent plots to the "bw" theme. This theme is characterized by a white background, black text, and a minimalist aesthetic.
```

# construction of a simple sample data.frame from the information encoded in the filenames
```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```

#now construct a phyloseq object directly from the dada2 outputs.
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```

#It is more convenient to use short names for our ASVs (e.g. ASV21) rather than the full DNA sequence when working with some of the tables and visualizations from phyloseq, but we want to keep the full DNA sequences for other purposes like merging with other datasets or indexing into reference databases like the Earth Microbiome Project. For that reason we’ll store the DNA sequences of our ASVs in the refseq slot of the phyloseq object, and then rename our taxa to a short string. That way, the short new taxa names will appear in tables and plots, and we can still recover the DNA sequences corresponding to each ASV as needed with refseq(ps).
```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```
#end of data preparation for phyloseq analysis. Now we proceed with the phyloseq analysis.
```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```
